{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 5: Shallow Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_valid, y_valid) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what a '5' looks like in numpy array from MNIST-digit database\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0],cmap='cool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for i in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    plt.subplot(3,4, i+1)\n",
    "    plt.imshow(X_train[i],cmap='Greys')\n",
    "    plt.axis('off')\n",
    "#plt.tight_layout()\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    plt.subplot(3,4, i+1)\n",
    "    plt.imshow(X_train[i],cmap='Greys')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshapes to 2D and changes type ('float' is a 32-bit; not doing this change Python uses the default: 64-bit... less pc usage)\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1]*X_train.shape[2]).astype('float32')\n",
    "X_valid = X_valid.reshape(X_valid.shape[0],X_valid.shape[1]*X_valid.shape[2]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'unit8' stores integer between 0 to 255:\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing it to values from 0 to 1:\n",
    "X_train /= 255\n",
    "X_valid /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this was what a \"5\" looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### transforming it to One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10 # 10 target variables (ie number form 0 to 9)\n",
    "y_train = tf.keras.utils.to_categorical(y_train,n_classes)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of Model\n",
    "model = Sequential()\n",
    "\n",
    "# Hidden Layer: 64 neurons\n",
    "model.add( Dense(64, activation='sigmoid', input_shape=(X_train.shape[1],) ) )\n",
    "\n",
    "# Output Layer:\n",
    "model.add( Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,\n",
    "         batch_size=(64*2), # double number of neurons,\n",
    "         epochs=200, # number of cycles the network is trained\n",
    "         verbose=1, # progress bar\n",
    "         validation_data=(X_valid,y_valid)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intermediate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2= Sequential()\n",
    "\n",
    "# Hidden Layer: 64 neurons\n",
    "model2.add( Dense(64, activation='relu', input_shape=(X_train.shape[1],) ) ) # uses ReLu as activation instead of sigmoid\n",
    "\n",
    "# 2nd Hidden Layer: 64 neurons\n",
    "model2.add( Dense(64, activation='relu')) # additional hidden layer (Intermediate) instead of 1 (Shallow)\n",
    "\n",
    "# Output Layer: 10 possible outcomes\n",
    "model2.add( Dense(10, activation='softmax') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', # instead of 'MSE' -also 'binary_crossentropy'  if signoid is used as activation\n",
    "              optimizer=SGD(lr=.1), # instead of 0.01\n",
    "              metrics=['accuracy']\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(X_train, y_train,\n",
    "         batch_size=128,\n",
    "         epochs=20, # instead of 200\n",
    "         verbose=1,\n",
    "         validation_data=(X_valid,y_valid)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion: using ReLu as activation function, an additional Hidden Layer, and Cross Entropy as Loss function, alll these increases efficiency (ie time to compute) and accuracy (97% vs 87%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Deep Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight and Bias Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation\n",
    "from keras.initializers import Zeros, RandomNormal\n",
    "from keras.initializers import glorot_normal, glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing Biases as Zeros\n",
    "b_init = Zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing Weights as Glorot Distribution Random numbers\n",
    "w_init = glorot_normal() # alternative glorot_uniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "# Hidden Layer: 64*4 neurons\n",
    "model3.add( Dense(64*4, activation='relu', input_shape=(X_train.shape[1],) , # uses sigmoid instead of ReLu\n",
    "                 kernel_initializer=w_init, # Glorot Random\n",
    "                 bias_initializer=b_init) ) # Zeros\n",
    "\n",
    "# 2nd Hidden Layer: 64*2 neurons\n",
    "model3.add( Dense(64*2, activation='relu')) # additional hidden layer (Intermediate) instead of 1 (Shallow)\n",
    "\n",
    "# Output Layer: 10 possible outcomes\n",
    "model3.add( Dense(10, activation='softmax') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='categorical_crossentropy', # instead of 'MSE' -also 'binary_crossentropy' if signoid is used as activation\n",
    "              optimizer=SGD(lr=.1), # instead of 0.01\n",
    "              metrics=['accuracy']\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.fit(X_train, y_train,\n",
    "         batch_size=128,\n",
    "         epochs=20, # instead of 200\n",
    "         verbose=1,\n",
    "         validation_data=(X_valid,y_valid)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "\n",
    "# Hidden Layer: 64*4 neurons\n",
    "model4.add( Dense(64*4, activation='relu', input_shape=(X_train.shape[1],) , \n",
    "                 kernel_initializer=glorot_normal(), \n",
    "                 bias_initializer=b_init) ) \n",
    "model4.add(BatchNormalization() ) # Batch Normalization\n",
    "\n",
    "# 2nd Hidden Layer: 64*2 neurons\n",
    "model4.add( Dense(64*2, activation='relu')) \n",
    "model4.add(BatchNormalization() ) # Batch Normalization\n",
    "\n",
    "# Output Layer: 10 possible outcomes\n",
    "model4.add( Dense(10, activation='softmax') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(loss='categorical_crossentropy', # instead of MSE\n",
    "              optimizer=SGD(lr=.1), # instead of 0.01\n",
    "              metrics=['accuracy']\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.fit(X_train, y_train,\n",
    "         batch_size=128,\n",
    "         epochs=20, # instead of 200\n",
    "         verbose=1,\n",
    "         validation_data=(X_valid,y_valid)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fancy Optimizers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Momentum\n",
    "tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False, name='SGD')\n",
    "\n",
    "Nesterov\n",
    "tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=True, name='SGD')\n",
    "\n",
    "AdaGrad\n",
    "tf.keras.optimizers.Adagrad(learning_rate=0.001, initial_accumulator_value=0.1, epsilon=1e-07)\n",
    "\n",
    "AdaDelta\n",
    "tf.keras.optimizers.Adadelta(learning_rate=0.001, rho=0.95, epsilon=1e-07, name='Adadelta')\n",
    "\n",
    "RMSProp\n",
    "tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,name='RMSprop')\n",
    "\n",
    "Adam\n",
    "tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,name='Adam')\n",
    "\n",
    "Adam with Nesterov\n",
    "tf.keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07,name='Nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07,name='Nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "\n",
    "model5.add( Dense(64*4, activation='relu', input_shape=(X_train.shape[1],) , \n",
    "                 kernel_initializer=glorot_normal(), \n",
    "                 bias_initializer=b_init) ) \n",
    "model5.add(BatchNormalization() )\n",
    "\n",
    "model5.add( Dense(64*2, activation='relu')) \n",
    "model5.add(BatchNormalization() )\n",
    "\n",
    "model5.add( Dense(10, activation='softmax') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.fit(X_train, y_train,batch_size=128,epochs=20, verbose=0,validation_data=(X_valid,y_valid) )\n",
    "\n",
    "model5.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0705 - accuracy: 0.9832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07053099572658539, 0.9832000136375427]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.1, initial_accumulator_value=0.1, epsilon=1e-07)\n",
    "\n",
    "# Model Design (3 layers)\n",
    "model_ = Sequential()\n",
    "model_.add(Dense(64*4,activation='relu',input_shape=(X_train.shape[1],),kernel_initializer=glorot_normal(),bias_initializer=Zeros()) ) \n",
    "model_.add(BatchNormalization() )\n",
    "\n",
    "model_.add(Dense(64*2, activation='relu')) \n",
    "model_.add(BatchNormalization() )\n",
    "\n",
    "model_.add(Dense(64, activation='relu')) \n",
    "model_.add(BatchNormalization() )\n",
    "\n",
    "model_.add(Dense(10, activation='softmax') )\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "model_.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "\n",
    "# Fit and Evaluation\n",
    "model_.fit(X_train, y_train,batch_size=128,epochs=20, verbose=0,validation_data=(X_valid,y_valid) )\n",
    "\n",
    "model_.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting (Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 3s 4ms/step - loss: 0.4902 - accuracy: 0.8565 - val_loss: 0.1787 - val_accuracy: 0.9464\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2595 - accuracy: 0.9254 - val_loss: 0.1414 - val_accuracy: 0.9589\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2095 - accuracy: 0.9395 - val_loss: 0.1701 - val_accuracy: 0.9522\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1796 - accuracy: 0.9484 - val_loss: 0.1323 - val_accuracy: 0.9647\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1628 - accuracy: 0.9525 - val_loss: 0.1040 - val_accuracy: 0.9697\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1480 - accuracy: 0.9561 - val_loss: 0.1033 - val_accuracy: 0.9727\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1345 - accuracy: 0.9586 - val_loss: 0.1005 - val_accuracy: 0.9730\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1288 - accuracy: 0.9597 - val_loss: 0.0962 - val_accuracy: 0.9749\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1179 - accuracy: 0.9627 - val_loss: 0.1013 - val_accuracy: 0.9738\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1109 - accuracy: 0.9647 - val_loss: 0.1067 - val_accuracy: 0.9748\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1093 - accuracy: 0.9647 - val_loss: 0.0990 - val_accuracy: 0.9743\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1019 - accuracy: 0.9675 - val_loss: 0.1020 - val_accuracy: 0.9760\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0923 - accuracy: 0.9696 - val_loss: 0.1046 - val_accuracy: 0.9746\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0920 - accuracy: 0.9702 - val_loss: 0.1008 - val_accuracy: 0.9758\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0900 - accuracy: 0.9699 - val_loss: 0.1020 - val_accuracy: 0.9763\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0880 - accuracy: 0.9707 - val_loss: 0.0976 - val_accuracy: 0.9774\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0789 - accuracy: 0.9725 - val_loss: 0.1043 - val_accuracy: 0.9757\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0803 - accuracy: 0.9725 - val_loss: 0.0994 - val_accuracy: 0.9772\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0782 - accuracy: 0.9720 - val_loss: 0.1146 - val_accuracy: 0.9742\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0730 - accuracy: 0.9743 - val_loss: 0.1236 - val_accuracy: 0.9724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e32a8d12b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1236206665635109, 0.9724000096321106]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.1, initial_accumulator_value=0.1, epsilon=1e-07)\n",
    "\n",
    "# Model Design (3 layers)\n",
    "model_ = Sequential()\n",
    "model_.add(Dense(64,activation='relu',input_shape=(X_train.shape[1],),kernel_initializer=glorot_normal(),bias_initializer=Zeros()) ) \n",
    "model_.add(BatchNormalization() )\n",
    "\n",
    "model_.add(Dense(32, activation='relu')) \n",
    "model_.add(BatchNormalization() )\n",
    "\n",
    "model_.add(Dense(16, activation='relu')) \n",
    "model_.add(BatchNormalization() )\n",
    "model_.add(Dropout(0.5)) # droput rate\n",
    "\n",
    "model_.add(Dense(10, activation='softmax') )\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "model_.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "\n",
    "# Fit and Evaluation\n",
    "display(model_.fit(X_train, y_train,batch_size=128,epochs=20, verbose=1,validation_data=(X_valid,y_valid) ))\n",
    "\n",
    "display(model_.evaluate(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard # new!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set TensorBoard logging directory\n",
    "tensorboard = TensorBoard('logs/deep-net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyterlab in c:\\users\\public\\anaconda3\\lib\\site-packages (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: notebook>=4.3.1 in c:\\users\\public\\anaconda3\\lib\\site-packages (from jupyterlab) (6.0.3)\n",
      "Requirement already satisfied: tornado!=6.0.0,!=6.0.1,!=6.0.2 in c:\\users\\public\\anaconda3\\lib\\site-packages (from jupyterlab) (6.0.4)\n",
      "Requirement already satisfied: jupyterlab_server<2.0,>=1.1.0 in c:\\users\\public\\anaconda3\\lib\\site-packages (from jupyterlab) (1.2.0)\n",
      "Requirement already satisfied: jinja2>=2.10 in c:\\users\\public\\anaconda3\\lib\\site-packages (from jupyterlab) (2.11.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in c:\\users\\public\\anaconda3\\lib\\site-packages (from notebook>=4.3.1->jupyterlab) (4.6.3)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\public\\anaconda3\\lib\\site-packages (from notebook>=4.3.1->jupyterlab) (0.2.0)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\public\\anaconda3\\lib\\site-packages (from notebook>=4.3.1->jupyterlab) (19.0.1)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in c:\\users\\public\\anaconda3\\lib\\site-packages (from notebook>=4.3.1->jupyterlab) (6.1.6)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\public\\anaconda3\\lib\\site-packages (from notebook>=4.3.1->jupyterlab) (1.5.0)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\public\\anaconda3\\lib\\site-packages (from notebook>=4.3.1->jupyterlab) (5.6.1)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\public\\anaconda3\\lib\\site-packages (from notebook>=4.3.1->jupyterlab) (0.8.0)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\public\\anaconda3\\lib\\site-packages (from notebook>=4.3.1->jupyterlab) (5.3.2)\n",
      "Requirement already satisfied: nbformat in c:\\users\\public\\anaconda3\\lib\\site-packages (from notebook>=4.3.1->jupyterlab) (5.0.7)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in c:\\users\\public\\anaconda3\\lib\\site-packages (from notebook>=4.3.1->jupyterlab) (4.3.3)\n",
      "Requirement already satisfied: terminado>=0.8.1 in c:\\users\\public\\anaconda3\\lib\\site-packages (from notebook>=4.3.1->jupyterlab) (0.8.3)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in c:\\users\\public\\anaconda3\\lib\\site-packages (from jupyterlab_server<2.0,>=1.1.0->jupyterlab) (3.2.0)\n",
      "Requirement already satisfied: json5 in c:\\users\\public\\anaconda3\\lib\\site-packages (from jupyterlab_server<2.0,>=1.1.0->jupyterlab) (0.9.5)\n",
      "Requirement already satisfied: requests in c:\\users\\public\\anaconda3\\lib\\site-packages (from jupyterlab_server<2.0,>=1.1.0->jupyterlab) (2.24.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\public\\anaconda3\\lib\\site-packages (from jinja2>=2.10->jupyterlab) (1.1.1)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\public\\anaconda3\\lib\\site-packages (from jupyter-core>=4.6.1->notebook>=4.3.1->jupyterlab) (227)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\public\\anaconda3\\lib\\site-packages (from jupyter-client>=5.3.4->notebook>=4.3.1->jupyterlab) (2.8.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\public\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (1.4.2)\n",
      "Requirement already satisfied: pygments in c:\\users\\public\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (2.6.1)\n",
      "Requirement already satisfied: testpath in c:\\users\\public\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.4.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\public\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.3)\n",
      "Requirement already satisfied: bleach in c:\\users\\public\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (3.1.5)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\public\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.6.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\public\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.3.1->jupyterlab) (0.8.4)\n",
      "Requirement already satisfied: ipython>=5.0.0 in c:\\users\\public\\anaconda3\\lib\\site-packages (from ipykernel->notebook>=4.3.1->jupyterlab) (7.16.1)\n",
      "Requirement already satisfied: six in c:\\users\\public\\anaconda3\\lib\\site-packages (from traitlets>=4.2.1->notebook>=4.3.1->jupyterlab) (1.15.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\public\\anaconda3\\lib\\site-packages (from traitlets>=4.2.1->notebook>=4.3.1->jupyterlab) (4.4.2)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\public\\anaconda3\\lib\\site-packages (from jsonschema>=3.0.1->jupyterlab_server<2.0,>=1.1.0->jupyterlab) (0.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\public\\anaconda3\\lib\\site-packages (from jsonschema>=3.0.1->jupyterlab_server<2.0,>=1.1.0->jupyterlab) (49.2.0.post20200714)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\public\\anaconda3\\lib\\site-packages (from jsonschema>=3.0.1->jupyterlab_server<2.0,>=1.1.0->jupyterlab) (19.3.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\public\\anaconda3\\lib\\site-packages (from requests->jupyterlab_server<2.0,>=1.1.0->jupyterlab) (1.25.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\public\\anaconda3\\lib\\site-packages (from requests->jupyterlab_server<2.0,>=1.1.0->jupyterlab) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\public\\anaconda3\\lib\\site-packages (from requests->jupyterlab_server<2.0,>=1.1.0->jupyterlab) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\public\\anaconda3\\lib\\site-packages (from requests->jupyterlab_server<2.0,>=1.1.0->jupyterlab) (2.10)\n",
      "Requirement already satisfied: packaging in c:\\users\\public\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.3.1->jupyterlab) (20.4)\n",
      "Requirement already satisfied: webencodings in c:\\users\\public\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.3.1->jupyterlab) (0.5.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\public\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (3.0.5)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\public\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.17.1)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\public\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.4.3)\n",
      "Requirement already satisfied: backcall in c:\\users\\public\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\public\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.7.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\public\\anaconda3\\lib\\site-packages (from packaging->bleach->nbconvert->notebook>=4.3.1->jupyterlab) (2.4.7)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\public\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.2.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\public\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->notebook>=4.3.1->jupyterlab) (0.7.0)\n"
     ]
    }
   ],
   "source": [
    "pip install jupyterlab"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for JupyterLab's Terminal go to\n",
    "http://localhost:8888/lab"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "write this on Terminal on same directory where this notebook was saved:\n",
    "tensorboard --logdir='logs/deep-net' --port 6006"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for TensorBoard go to\n",
    "http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0698 - accuracy: 0.9746 - val_loss: 0.1231 - val_accuracy: 0.9742\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0738 - accuracy: 0.9737 - val_loss: 0.1153 - val_accuracy: 0.9754\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0682 - accuracy: 0.9754 - val_loss: 0.0992 - val_accuracy: 0.9781\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0639 - accuracy: 0.9773 - val_loss: 0.1168 - val_accuracy: 0.9774\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0646 - accuracy: 0.9767 - val_loss: 0.1151 - val_accuracy: 0.9745\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0626 - accuracy: 0.9773 - val_loss: 0.1168 - val_accuracy: 0.9791\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0599 - accuracy: 0.9783 - val_loss: 0.1210 - val_accuracy: 0.9764\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0585 - accuracy: 0.9786 - val_loss: 0.1260 - val_accuracy: 0.9748\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0575 - accuracy: 0.9789 - val_loss: 0.1250 - val_accuracy: 0.9760\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0566 - accuracy: 0.9796 - val_loss: 0.1278 - val_accuracy: 0.9755\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0564 - accuracy: 0.9795 - val_loss: 0.1272 - val_accuracy: 0.9758\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0560 - accuracy: 0.9794 - val_loss: 0.1362 - val_accuracy: 0.9751\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0533 - accuracy: 0.9803 - val_loss: 0.1286 - val_accuracy: 0.9772\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.1347 - val_accuracy: 0.9765\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0508 - accuracy: 0.9809 - val_loss: 0.1319 - val_accuracy: 0.9756\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0525 - accuracy: 0.9801 - val_loss: 0.1294 - val_accuracy: 0.9755\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0522 - accuracy: 0.9799 - val_loss: 0.1327 - val_accuracy: 0.9758\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0506 - accuracy: 0.9812 - val_loss: 0.1347 - val_accuracy: 0.9762\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0499 - accuracy: 0.9812 - val_loss: 0.1437 - val_accuracy: 0.9757\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0505 - accuracy: 0.9805 - val_loss: 0.1281 - val_accuracy: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e32f892640>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.fit(X_train, y_train,batch_size=128,epochs=20, verbose=1,validation_data=(X_valid,y_valid),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression (Boston Housing Prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 0us/step\n",
      "65536/57026 [==================================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(Xtrain, ytrain), (Xvalid, yvalid) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (404,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Xtrain.shape, ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.23247,   0.     ,   8.14   ,   0.     ,   0.538  ,   6.142  ,\n",
       "         91.7    ,   3.9769 ,   4.     , 307.     ,  21.     , 396.9    ,\n",
       "         18.72   ]),\n",
       " 15.2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Xtrain[0], ytrain[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intermediate Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg = Sequential()\n",
    "\n",
    "model_reg.add(Dense(32, input_dim=13, activation='relu'))\n",
    "model_reg.add(BatchNormalization())\n",
    "\n",
    "model_reg.add(Dense(16, activation='relu'))\n",
    "model_reg.add(BatchNormalization())\n",
    "model_reg.add(Dropout(0.2))\n",
    "\n",
    "model_reg.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 32)                448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,185\n",
      "Trainable params: 1,089\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### .train vs .fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using .train and .predict\n",
    "model_reg.train(Xtrain, ytrain, batch_size=8, epochs=32, verbose=1)\n",
    "model_reg.predict(Xvalid, yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "51/51 [==============================] - 1s 5ms/step - loss: 573.0999 - val_loss: 658.1178\n",
      "Epoch 2/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 553.3770 - val_loss: 630.7463\n",
      "Epoch 3/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 535.4413 - val_loss: 585.5446\n",
      "Epoch 4/32\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 514.1288 - val_loss: 542.7508\n",
      "Epoch 5/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 493.1631 - val_loss: 499.7548\n",
      "Epoch 6/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 462.9146 - val_loss: 424.8047\n",
      "Epoch 7/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 434.8048 - val_loss: 374.3062\n",
      "Epoch 8/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 403.8837 - val_loss: 321.0039\n",
      "Epoch 9/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 363.0887 - val_loss: 290.5109\n",
      "Epoch 10/32\n",
      "51/51 [==============================] - 0s 4ms/step - loss: 329.9040 - val_loss: 274.9150\n",
      "Epoch 11/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 284.9360 - val_loss: 266.1043\n",
      "Epoch 12/32\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 252.8783 - val_loss: 303.2116\n",
      "Epoch 13/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 207.9394 - val_loss: 281.2119\n",
      "Epoch 14/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 174.5275 - val_loss: 167.1753\n",
      "Epoch 15/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 140.6413 - val_loss: 130.8404\n",
      "Epoch 16/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 125.3249 - val_loss: 137.5949\n",
      "Epoch 17/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 101.6478 - val_loss: 111.3108\n",
      "Epoch 18/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 85.7981 - val_loss: 146.1730\n",
      "Epoch 19/32\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 69.8171 - val_loss: 142.5060\n",
      "Epoch 20/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 60.9510 - val_loss: 124.2899\n",
      "Epoch 21/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 64.8327 - val_loss: 36.5516\n",
      "Epoch 22/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 54.5791 - val_loss: 52.2878\n",
      "Epoch 23/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 57.4387 - val_loss: 35.5851\n",
      "Epoch 24/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 55.8027 - val_loss: 60.5650\n",
      "Epoch 25/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 47.8688 - val_loss: 36.4937\n",
      "Epoch 26/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 46.6100 - val_loss: 23.8424\n",
      "Epoch 27/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 45.2785 - val_loss: 89.2272\n",
      "Epoch 28/32\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 45.9888 - val_loss: 52.2578\n",
      "Epoch 29/32\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 41.0669 - val_loss: 37.5489\n",
      "Epoch 30/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 49.2896 - val_loss: 27.6149\n",
      "Epoch 31/32\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 45.9330 - val_loss: 62.3932\n",
      "Epoch 32/32\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 48.0026 - val_loss: 37.3870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e32a0c7850>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using .fit\n",
    "model_reg.fit(Xtrain, ytrain,\n",
    "              batch_size=8, epochs=32, verbose=1, \n",
    "              validation_data=(Xvalid, yvalid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 37.3870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37.38697052001953"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not useful for regression models:\n",
    "model_reg.evaluate(Xvalid, yvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35.72557]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reg.predict(np.reshape(Xvalid[27], [1, Xtrain.shape[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding Response Variable to Categorical Codes via Kers' to_categorical"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.response_col = pd.Categorical(df.response_col)\n",
    "df.response_col = df.response_col.cat.codes\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "competitors = to_categorical(df.response_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
